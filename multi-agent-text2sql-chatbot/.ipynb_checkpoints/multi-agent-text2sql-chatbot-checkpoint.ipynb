{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6332443f-1f5d-4e8e-a7d2-bd0f32483dfc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Source\n",
    "\n",
    "https://pub.towardsai.net/agentic-ai-project-build-multi-agent-text2sql-chatbot-for-ecommerce-database-c8d0e294ec94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597a15c-9c20-41ae-963c-adc2f7ed839b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tech Stack & Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2badbd22-f806-4f33-8d3a-b8683427f75d",
   "metadata": {},
   "source": [
    "- Tech Stack & Architecture\n",
    "    - Core Framework → LangGraph\n",
    "    - Front End: Chainlit\n",
    "    - AI & LLM → OpenAI API (gpt-4-mini)\n",
    "    - Data & Database → SQLite3, Pandas, Brazilian E-Commerce Dataset (Olist)\n",
    "    - Visualization → Plotly, LLM-Generated Visualization Code\n",
    "    - Utilities → python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3a7c5-6607-45b6-86e3-9691aebf79ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1477cec-f4e3-400d-8788-1f3b398ce72a",
   "metadata": {},
   "source": [
    "- Data: Customer (olist_customers_dataset.csv)\n",
    "- Data: Geo Location (olist_geolocation_dataset.csv)\n",
    "- Data: Order Items (olist_order_items_dataset.csv)\n",
    "- Data: Order Payments (olist_order_payments_dataset.csv)\n",
    "- Data: Order Reviews (olist_order_reviews_dataset.csv)\n",
    "- Data: Orders (olist_orders_dataset.csv)\n",
    "- Data: Products (olist_products_dataset.csv)\n",
    "- Data Sellers (olist_sellers_dataset.csv)\n",
    "- Data: Product Category Translation (product_category_name_translation.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a82292d7-9905-4fe0-b584-7587ddee1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9fae39e9-f5d2-4607-8a62-46957bfea181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (99441, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        customer_id                customer_unique_id  \\\n",
       "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "\n",
       "   customer_zip_code_prefix          customer_city customer_state  \n",
       "0                     14409                 franca             SP  \n",
       "1                      9790  sao bernardo do campo             SP  \n",
       "2                      1151              sao paulo             SP  \n",
       "3                      8775        mogi das cruzes             SP  \n",
       "4                     13056               campinas             SP  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df = pd.read_csv(\"data/olist_customers_dataset.csv\")\n",
    "print(f\"Shape: {customers_df.shape}\")\n",
    "customers_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0a840-dbed-4b2e-b246-3eeb1237e844",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create the SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67908dd9-5b94-4946-880f-5de44e4fca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2beb3ab-60fc-4b31-ac52-cf39a0b0b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: olist_customers_dataset.csv -> customers table (99441 rows, 5 columns)\n",
      "Loaded: olist_orders_dataset.csv -> orders table (99441 rows, 8 columns)\n",
      "Loaded: olist_order_items_dataset.csv -> order_items table (112650 rows, 7 columns)\n",
      "Loaded: olist_order_payments_dataset.csv -> order_payments table (103886 rows, 5 columns)\n",
      "Loaded: olist_order_reviews_dataset.csv -> order_reviews table (99224 rows, 7 columns)\n",
      "Loaded: olist_products_dataset.csv -> products table (32951 rows, 9 columns)\n",
      "Loaded: olist_sellers_dataset.csv -> sellers table (3095 rows, 4 columns)\n",
      "Loaded: olist_geolocation_dataset.csv -> geolocation table (1000163 rows, 5 columns)\n",
      "Loaded: product_category_name_translation.csv -> product_category_name_translation table (71 rows, 2 columns)\n",
      "\n",
      "Database created: ecommerce.db\n",
      "Tables: customers, orders, order_items, order_payments, order_reviews, products, sellers, geolocation, product_category_name_translation\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data\"\n",
    "db = \"ecommerce.db\"\n",
    "\n",
    "if os.path.exists(db):\n",
    "    os.remove(db)\n",
    "\n",
    "conn = sqlite3.connect(db)\n",
    "\n",
    "def load(name):\n",
    "    df = pd.read_csv(f\"{data_path}/{name}\")\n",
    "    table_name = name.replace(\"olist_\",\"\").replace(\"_dataset.csv\",\"\").replace(\".csv\",\"\")\n",
    "    df.to_sql(table_name, conn, index=False, if_exists=\"replace\")\n",
    "    print(f\"Loaded: {name} -> {table_name} table ({df.shape[0]} rows, {df.shape[1]} columns)\")\n",
    "\n",
    "# Load all datasets\n",
    "load(\"olist_customers_dataset.csv\")\n",
    "load(\"olist_orders_dataset.csv\")\n",
    "load(\"olist_order_items_dataset.csv\")\n",
    "load(\"olist_order_payments_dataset.csv\")\n",
    "load(\"olist_order_reviews_dataset.csv\")\n",
    "load(\"olist_products_dataset.csv\")\n",
    "load(\"olist_sellers_dataset.csv\")\n",
    "load(\"olist_geolocation_dataset.csv\")\n",
    "load(\"product_category_name_translation.csv\")\n",
    "\n",
    "conn.close()\n",
    "print(f\"\\nDatabase created: {db}\")\n",
    "print(\"Tables: customers, orders, order_items, order_payments, order_reviews, products, sellers, geolocation, product_category_name_translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7bb4df-2cdd-4f8a-8624-b036e2e3b748",
   "metadata": {},
   "source": [
    "# Text-to-SQL Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437de37-bfd0-480f-bdf1-3c1c3f628a66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports and Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d591045e-88da-4f92-bb04-4c526a2eae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58a1ea0e-47e3-425b-9141-7b9305e36887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Key Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI Key\n",
    "load_dotenv()\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    print(\"OpenAI Key Loaded.\")\n",
    "else:\n",
    "    print(\"OpenAI Key not-Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c8ebf-3a17-44fe-a290-0925ed35bcc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Defining the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a667c79-3ac6-48c2-a95e-9b0e02ae9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database schema information\n",
    "SCHEMA_INFO = \"\"\"\n",
    "Database Schema for E-commerce System:\n",
    "\n",
    "1. customers\n",
    "   - customer_id (TEXT): Unique customer identifier\n",
    "   - customer_unique_id (TEXT): Unique customer identifier across datasets\n",
    "   - customer_zip_code_prefix (INTEGER): Customer zip code\n",
    "   - customer_city (TEXT): Customer city\n",
    "   - customer_state (TEXT): Customer state\n",
    "\n",
    "2. orders\n",
    "   - order_id (TEXT): Unique order identifier\n",
    "   - customer_id (TEXT): Foreign key to customers\n",
    "   - order_status (TEXT): Order status (delivered, shipped, etc.)\n",
    "   - order_purchase_timestamp (TEXT): When the order was placed\n",
    "   - order_approved_at (TEXT): When payment was approved\n",
    "   - order_delivered_carrier_date (TEXT): When order was handed to carrier\n",
    "   - order_delivered_customer_date (TEXT): When customer received the order\n",
    "   - order_estimated_delivery_date (TEXT): Estimated delivery date\n",
    "\n",
    "3. order_items\n",
    "   - order_id (TEXT): Foreign key to orders\n",
    "   - order_item_id (INTEGER): Item sequence number within order\n",
    "   - product_id (TEXT): Foreign key to products\n",
    "   - seller_id (TEXT): Foreign key to sellers\n",
    "   - shipping_limit_date (TEXT): Shipping deadline\n",
    "   - price (REAL): Item price\n",
    "   - freight_value (REAL): Shipping cost\n",
    "\n",
    "4. order_payments\n",
    "   - order_id (TEXT): Foreign key to orders\n",
    "   - payment_sequential (INTEGER): Payment sequence number\n",
    "   - payment_type (TEXT): Payment method (credit_card, boleto, etc.)\n",
    "   - payment_installments (INTEGER): Number of installments\n",
    "   - payment_value (REAL): Payment amount\n",
    "\n",
    "5. order_reviews\n",
    "   - review_id (TEXT): Unique review identifier\n",
    "   - order_id (TEXT): Foreign key to orders\n",
    "   - review_score (INTEGER): Review score (1-5)\n",
    "   - review_comment_title (TEXT): Review title\n",
    "   - review_comment_message (TEXT): Review message\n",
    "   - review_creation_date (TEXT): When review was created\n",
    "   - review_answer_timestamp (TEXT): When review was answered\n",
    "\n",
    "6. products\n",
    "   - product_id (TEXT): Unique product identifier\n",
    "   - product_category_name (TEXT): Product category (in Portuguese)\n",
    "   - product_name_lenght (REAL): Product name length\n",
    "   - product_description_lenght (REAL): Product description length\n",
    "   - product_photos_qty (REAL): Number of product photos\n",
    "   - product_weight_g (REAL): Product weight in grams\n",
    "   - product_length_cm (REAL): Product length in cm\n",
    "   - product_height_cm (REAL): Product height in cm\n",
    "   - product_width_cm (REAL): Product width in cm\n",
    "\n",
    "7. sellers\n",
    "   - seller_id (TEXT): Unique seller identifier\n",
    "   - seller_zip_code_prefix (INTEGER): Seller zip code\n",
    "   - seller_city (TEXT): Seller city\n",
    "   - seller_state (TEXT): Seller state\n",
    "\n",
    "8. geolocation\n",
    "   - geolocation_zip_code_prefix (INTEGER): Zip code prefix\n",
    "   - geolocation_lat (REAL): Latitude\n",
    "   - geolocation_lng (REAL): Longitude\n",
    "   - geolocation_city (TEXT): City name\n",
    "   - geolocation_state (TEXT): State code\n",
    "\n",
    "9. product_category_name_translation\n",
    "   - product_category_name (TEXT): Category name in Portuguese\n",
    "   - product_category_name_english (TEXT): Category name in English\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e742e0-f2ed-4f74-afe6-06fe61a85ebf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "709124d7-5ff1-4c44-8421-b8722309e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the agent workflow\"\"\"\n",
    "    question: str\n",
    "    sql_query: str\n",
    "    query_result: str\n",
    "    final_answer: str\n",
    "    error: str\n",
    "    iteration: int\n",
    "    needs_graph: bool\n",
    "    graph_type: str\n",
    "    graph_json: str  # Plotly figure JSON for Chainlit\n",
    "    is_in_scope: bool  # Whether the question is about e-commerce data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1bf332-4a27-4fc5-93bf-976d87c3905a",
   "metadata": {},
   "source": [
    "## Agent Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ef99292-7779-4f55-a402-a073905de634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent configurations with different roles and personalities\n",
    "AGENT_CONFIGS = {\n",
    "    \"guardrails_agent\": {\n",
    "        \"role\": \"Security and Scope Manager\",\n",
    "        \"system_prompt\": \"You are a strict guardrails system that filters questions to ensure they are relevant to e-commerce data analysis or identifies greetings.\",\n",
    "    },\n",
    "    \"sql_agent\": {\n",
    "        \"role\": \"SQL Expert\", \n",
    "        \"system_prompt\": \"You are a senior SQL developer specializing in e-commerce databases. Generate only valid SQLite queries without any formatting or explanation.\",\n",
    "    },\n",
    "    \"analysis_agent\": {\n",
    "        \"role\": \"Data Analyst\",\n",
    "        \"system_prompt\": \"You are a helpful data analyst that explains database query results in natural language with clear insights.\",\n",
    "    },\n",
    "    \"viz_agent\": {\n",
    "        \"role\": \"Visualization Specialist\", \n",
    "        \"system_prompt\": \"You are a data visualization expert. Generate clean, executable Plotly code without any markdown formatting or explanations.\",\n",
    "    },\n",
    "    \"error_agent\": {\n",
    "        \"role\": \"Error Recovery Specialist\",\n",
    "        \"system_prompt\": \"You diagnose and fix SQL errors with expert knowledge of database schemas and query optimization.\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35350a27-05a7-4b86-8c11-00f8180d2d0f",
   "metadata": {},
   "source": [
    "## Agent Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99defa-3ae4-485f-a752-ff73ab419979",
   "metadata": {},
   "source": [
    "### Agent: Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb3cce54-3367-4665-b6e8-12741b07ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardrails_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Check if the question is within scope (e-commerce related)\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a guardrails system for an e-commerce database chatbot. Your job is to determine if a user's question is related to e-commerce data, if it's a greeting, or if it's out of scope.\n",
    "\n",
    "The chatbot has access to an e-commerce database with information about:\n",
    "- Customers and their locations\n",
    "- Orders and order status (data from 2016-2018)\n",
    "- Products and categories\n",
    "- Sellers\n",
    "- Payments\n",
    "- Reviews\n",
    "- Shipping and delivery information\n",
    "\n",
    "Examples of GREETING messages:\n",
    "- \"Hi\", \"Hello\", \"Hey\"\n",
    "- \"Good morning\", \"Good afternoon\"\n",
    "- \"How are you?\"\n",
    "- Any casual greeting or introduction\n",
    "\n",
    "Examples of IN-SCOPE questions:\n",
    "- \"How many orders were placed last month?\"\n",
    "- \"What are the top selling products?\"\n",
    "- \"Show me customer distribution by state\"\n",
    "- \"What is the average order value?\"\n",
    "- \"Which sellers have the highest ratings?\"\n",
    "\n",
    "Examples of OUT-OF-SCOPE questions:\n",
    "- Personal questions (e.g., \"What is my wife's name?\", \"Where do I live?\")\n",
    "- Political questions (e.g., \"Who should I vote for?\", \"What do you think about the president?\")\n",
    "- General knowledge (e.g., \"What is the capital of France?\", \"How does photosynthesis work?\")\n",
    "- Unrelated topics (e.g., \"Tell me a joke\", \"What's the weather like?\")\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Analyze the question and respond in JSON format:\n",
    "{{\n",
    "    \"is_in_scope\": true/false,\n",
    "    \"is_greeting\": true/false,\n",
    "    \"reason\": \"brief explanation of why it is or isn't in scope or if it's a greeting\"\n",
    "}}\n",
    "\n",
    "If the question is a greeting, mark is_greeting as true and is_in_scope as false.\n",
    "If the question is ambiguous but could potentially relate to the e-commerce data, mark it as in_scope.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        message=[\n",
    "            {\"role\": \"system\", \"content\": AGENT_CONFIGS[\"guardrails_agent\"][\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    state[\"is_in_scope\"] = result.get(\"is_in_scope\", False)\n",
    "    is_greeting = result.get(\"is_greeting\", False)\n",
    "\n",
    "    # If it's a greeting, provide a welcome message\n",
    "    if is_greeting:\n",
    "        state[\"final_answer\"] = \"Hi! I am your e-commerce assistant. I can answer all the queries related to orders, customers, products, sellers, payments, and reviews between 2016-2018. How can I help you today?\"\n",
    "        return state\n",
    "    \n",
    "    # If out of scope, set the final answer immediately\n",
    "    if not state[\"is_in_scope\"]:\n",
    "        state[\"final_answer\"] = \"I apologize, but your question appears to be out of scope. I can only answer questions about the e-commerce data, including:\\n\\n- Customer information and locations\\n- Orders and order status\\n- Products and categories\\n- Sellers and their performance\\n- Payment information\\n- Reviews and ratings\\n- Shipping and delivery data\\n\\nPlease ask a question related to the e-commerce database.\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e283128-dbd6-4009-a44c-b6da99708b5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Agent: Text2SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4317b560-826c-4503-9d9a-8158ec2fa50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate SQL query from natural language question\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    \n",
    "    prompt = f\"\"\"You are a SQL expert. Convert the following natural language question into a valid SQLite query.\n",
    "\n",
    "{SCHEMA_INFO}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Important Guidelines:\n",
    "1. Use only the tables and columns mentioned in the schema\n",
    "2. Use proper JOIN clauses when querying multiple tables\n",
    "3. Return ONLY the SQL query without any explanation or markdown formatting\n",
    "4. If the question contains multiple sub-questions, generate separate SQL queries separated by semicolons\n",
    "5. Use aggregate functions (COUNT, SUM, AVG, etc.) appropriately\n",
    "6. Add LIMIT clauses for queries that might return many rows (default LIMIT 10 unless user specifies)\n",
    "7. Use proper WHERE clauses to filter data\n",
    "8. For date comparisons, remember the dates are stored as TEXT in ISO format\n",
    "9. Each SQL statement should be on its own line for clarity when multiple queries are needed\n",
    "\n",
    "Generate the SQL query:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": AGENT_CONFIGS[\"sql_agent\"][\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    sql_query = response.choices[0].message.content.strip()\n",
    "    # Remove markdown code blocks if present\n",
    "    sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    state[\"sql_query\"] = sql_query\n",
    "    state[\"iteration\"] = iteration + 1\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "092ef733-a405-4edc-a784-9aeb7cbd900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(state: AgentState) -> AgentState:\n",
    "    \"\"\"Execute the generated SQL query (handles multiple queries if present)\"\"\"\n",
    "    sql_query = state[\"sql_query\"]\n",
    "    \n",
    "    try:\n",
    "        conn = sqlite3.connect(DB_PATH)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Split multiple SQL statements (separated by semicolons)\n",
    "        # Remove empty statements and strip whitespace\n",
    "        sql_statements = [stmt.strip() for stmt in sql_query.split(';') if stmt.strip()]\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        # Execute each statement separately\n",
    "        for i, statement in enumerate(sql_statements):\n",
    "            cursor.execute(statement)\n",
    "            \n",
    "            # Fetch results for this statement\n",
    "            results = cursor.fetchall()\n",
    "            \n",
    "            if results:\n",
    "                column_names = [description[0] for description in cursor.description]\n",
    "                \n",
    "                # Convert to list of dictionaries\n",
    "                formatted_results = []\n",
    "                for row in results[:100]:  # Limit to 100 rows per query\n",
    "                    formatted_results.append(dict(zip(column_names, row)))\n",
    "                \n",
    "                # If multiple queries, label them\n",
    "                if len(sql_statements) > 1:\n",
    "                    all_results.append({\n",
    "                        f\"query_{i+1}\": formatted_results,\n",
    "                        f\"query_{i+1}_sql\": statement\n",
    "                    })\n",
    "                else:\n",
    "                    all_results = formatted_results\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        # Format results\n",
    "        if not all_results:\n",
    "            state[\"query_result\"] = \"No results found.\"\n",
    "        else:\n",
    "            state[\"query_result\"] = json.dumps(all_results, indent=2)\n",
    "        \n",
    "        state[\"error\"] = \"\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"error\"] = f\"SQL Execution Error: {str(e)}\"\n",
    "        state[\"query_result\"] = \"\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1db84f-e326-44ea-be62-03c586c141f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Agent: Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0bf8cda-da9e-4f1a-8cdf-46673bb574d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Handle errors and attempt to fix the SQL query\"\"\"\n",
    "    error = state[\"error\"]\n",
    "    sql_query = state[\"sql_query\"]\n",
    "    question = state[\"question\"]\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    \n",
    "    # If we've tried too many times, give up\n",
    "    if iteration > 3:\n",
    "        state[\"final_answer\"] = f\"I apologize, but I'm having trouble generating a correct SQL query for your question. Error: {error}\"\n",
    "        return state\n",
    "    \n",
    "    prompt = f\"\"\"The following SQL query failed with an error. Please fix it.\n",
    "{SCHEMA_INFO}\n",
    "Original Question: {question}\n",
    "Failed SQL Query: {sql_query}\n",
    "Error: {error}\n",
    "Generate a corrected SQL query that will work. Return ONLY the SQL query without any explanation or markdown formatting:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": AGENT_CONFIGS[\"error_agent\"][\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    corrected_query = response.choices[0].message.content.strip()\n",
    "    corrected_query = corrected_query.replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    state[\"sql_query\"] = corrected_query\n",
    "    state[\"error\"] = \"\"  # Clear the error for retry\n",
    "    state[\"iteration\"] = iteration + 1  # Increment iteration counter\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4b11c-8eb2-4f7c-80e4-2bcf62f3634d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Agent: Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4ea3e8f-5678-46bf-960e-1d8a22ce815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate natural language answer from query results\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    sql_query = state[\"sql_query\"]\n",
    "    query_result = state[\"query_result\"]\n",
    "    \n",
    "    prompt = f\"\"\"You are a helpful assistant that explains database query results in natural language.\n",
    "\n",
    "Original Question: {question}\n",
    "SQL Query Used: {sql_query}\n",
    "Query Results:\n",
    "{query_result}\n",
    "\n",
    "Please provide a clear, concise answer to the original question based on the query results.\n",
    "Format the answer in a user-friendly way. If the results contain numbers, present them clearly.\n",
    "If there are multiple queries/results (for multi-part questions), address each part of the question separately.\n",
    "Use bullet points or numbered lists for multiple answers.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": AGENT_CONFIGS[\"analysis_agent\"][\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    final_answer = response.choices[0].message.content.strip()\n",
    "    state[\"final_answer\"] = final_answer\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f5bad-c88c-4e4f-942b-c04b29bbb799",
   "metadata": {},
   "source": [
    "### Agent: Decide Graph Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebe3c5dd-5757-4dd4-b6ac-e5fe5f78524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_graph_need(state: AgentState) -> AgentState:\n",
    "    \"\"\"Decide if a graph visualization would be helpful for the query\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    query_result = state[\"query_result\"]\n",
    "    \n",
    "    # If no results or error, no graph needed\n",
    "    if not query_result or query_result == \"No results found.\" or state.get(\"error\"):\n",
    "        state[\"needs_graph\"] = False\n",
    "        state[\"graph_type\"] = \"\"\n",
    "        return state\n",
    "    \n",
    "    prompt = f\"\"\"Analyze the following question and query results to determine if a graph visualization would be helpful.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Query Results Sample:\n",
    "{query_result[:500]}...\n",
    "\n",
    "Determine:\n",
    "1. Would a graph be helpful for this data? (YES/NO)\n",
    "2. If yes, what type of graph? (bar, line, pie, scatter)\n",
    "\n",
    "Consider:\n",
    "- Trends over time → line chart\n",
    "- Comparisons between categories → bar chart\n",
    "- Proportions/percentages → pie chart\n",
    "- Correlations → scatter plot\n",
    "- Simple counts or single values → NO graph needed\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\"needs_graph\": true/false, \"graph_type\": \"bar/line/pie/scatter/none\", \"reason\": \"brief explanation\"}}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data visualization expert. Analyze queries and determine if visualization would add value.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    decision = json.loads(response.choices[0].message.content)\n",
    "    state[\"needs_graph\"] = decision.get(\"needs_graph\", False)\n",
    "    state[\"graph_type\"] = decision.get(\"graph_type\", \"none\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d417d-4b16-434d-b548-15c6b6819c76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Agent: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f26f225a-dc51-4ec9-ad85-d95f8562df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate a graph visualization from query results using LLM-generated Plotly code\"\"\"\n",
    "    query_result = state[\"query_result\"]\n",
    "    graph_type = state[\"graph_type\"]\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    try:\n",
    "        # Parse query results\n",
    "        results = json.loads(query_result)\n",
    "        if not results or len(results) == 0:\n",
    "            state[\"graph_json\"] = \"\"\n",
    "            return state\n",
    "        \n",
    "        # Convert to DataFrame for context\n",
    "        df = pd.DataFrame(results)\n",
    "        columns = df.columns.tolist()\n",
    "        sample_data = df.head(5).to_dict('records')\n",
    "        \n",
    "        # Generate Plotly code using LLM\n",
    "        prompt = f\"\"\"Generate Python code using Plotly to visualize the following data.\n",
    "\n",
    "Question: {question}\n",
    "Graph Type: {graph_type}\n",
    "Columns: {columns}\n",
    "Sample Data (first 5 rows): {json.dumps(sample_data, indent=2)}\n",
    "Total Rows: {len(df)}\n",
    "\n",
    "Requirements:\n",
    "1. Use plotly.graph_objects or plotly.express\n",
    "2. The data is already loaded as 'df' (a pandas DataFrame)\n",
    "3. Create an appropriate {graph_type} chart\n",
    "4. Limit data to top 20 rows if there are many rows\n",
    "5. Add proper titles, labels, and formatting\n",
    "6. The figure variable must be named 'fig'\n",
    "7. Return ONLY the Python code, no explanations or markdown\n",
    "8. Do NOT include any import statements\n",
    "9. Do NOT include code to show the figure (no fig.show())\n",
    "10. Make the visualization visually appealing with appropriate colors and layout\n",
    "11. Update the layout for better interactivity (hover info, responsive sizing)\n",
    "\n",
    "Generate the Plotly code:\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": AGENT_CONFIGS[\"viz_agent\"][\"system_prompt\"]},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        plotly_code = response.choices[0].message.content.strip()\n",
    "        # Remove markdown code blocks if present\n",
    "        plotly_code = plotly_code.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        # Prepare execution environment\n",
    "        exec_globals = {\n",
    "            'df': df,\n",
    "            'pd': pd,\n",
    "            'json': json\n",
    "        }\n",
    "        \n",
    "        # Import plotly dynamically\n",
    "        try:\n",
    "            import plotly.graph_objects as go\n",
    "            import plotly.express as px\n",
    "            exec_globals['go'] = go\n",
    "            exec_globals['px'] = px\n",
    "        except ImportError:\n",
    "            print(\"Plotly not installed. Installing...\")\n",
    "            import subprocess\n",
    "            subprocess.check_call(['pip', 'install', 'plotly'])\n",
    "            import plotly.graph_objects as go\n",
    "            import plotly.express as px\n",
    "            exec_globals['go'] = go\n",
    "            exec_globals['px'] = px\n",
    "        \n",
    "        # Execute the generated code\n",
    "        exec(plotly_code, exec_globals)\n",
    "        \n",
    "        # Get the figure object\n",
    "        fig = exec_globals.get('fig')\n",
    "        \n",
    "        if fig is None:\n",
    "            raise ValueError(\"Generated code did not create a 'fig' variable\")\n",
    "        \n",
    "        # Export figure as JSON for Chainlit's Plotly element\n",
    "        graph_json = fig.to_json()\n",
    "        state[\"graph_json\"] = graph_json\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Graph generation error: {e}\")\n",
    "        print(f\"Generated code:\\n{plotly_code if 'plotly_code' in locals() else 'No code generated'}\")\n",
    "        state[\"graph_json\"] = \"\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31efa4fc-d376-4c98-b45b-dab7c8533a84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a107499c-d5f2-43bc-84a6-cc9591f8f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retry(state: AgentState) -> str:\n",
    "    \"\"\"Decide whether to retry after an error\"\"\"\n",
    "    if state.get(\"error\"):\n",
    "        iteration = state.get(\"iteration\", 0)\n",
    "        if iteration <= 3:\n",
    "            return \"retry\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "def should_generate_graph(state: AgentState) -> str:\n",
    "    \"\"\"Decide whether to generate a graph\"\"\"\n",
    "    if state.get(\"needs_graph\", False):\n",
    "        return \"viz_agent\"\n",
    "    return \"skip_graph\"\n",
    "\n",
    "\n",
    "def check_scope(state: AgentState) -> str:\n",
    "    \"\"\"Check if question is in scope to continue processing\"\"\"\n",
    "    if state.get(\"is_in_scope\", True):\n",
    "        return \"in_scope\"\n",
    "    return \"out_of_scope\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beaa0a5-8444-4eed-ae45-05e52f57348d",
   "metadata": {},
   "source": [
    "## LangGraph Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2eea824-9b20-4750-83f9-040adf128b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text2sql_graph():\n",
    "    \"\"\"Create the langhGraph state graph for Text2SQL with graph generation\"\"\"\n",
    "\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Add Nodes\n",
    "    workflow.add_node(\"guardrails_agent\", guardrails_agent)\n",
    "    workflow.add_node(\"sql_agent\", sql_agent)\n",
    "    workflow.add_node(\"execute_sql\", execute_sql)\n",
    "    workflow.add_node(\"analysis_agent\", analysis_agent)\n",
    "    workflow.add_node(\"error_agent\", error_agent)\n",
    "    workflow.add_node(\"decide_graph_need\", decide_graph_need)\n",
    "    workflow.add_node(\"viz_agent\", viz_agent)\n",
    "\n",
    "    # Add edges - start with guardrails check\n",
    "    workflow.set_entry_point(\"guardrails_agent\")\n",
    "\n",
    "    # Conditional edge from guardrails - only proceed if in scope\n",
    "    workflow.add_conditional_edges(\n",
    "        \"guardrails_agent\",\n",
    "        check_scope,\n",
    "        {\n",
    "            \"in_scope\": \"sql_agent\",\n",
    "            \"out_of_scope\": END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"sql_agent\", \"execute_sql\")\n",
    "\n",
    "    # Conditional edge based on execution success\n",
    "    workflow.add_conditional_edges(\n",
    "        \"execute_sql\",\n",
    "        should_retry,\n",
    "        {\n",
    "            \"success\": \"analysis_agent\",\n",
    "            \"retry\": \"error_agent\",\n",
    "            \"end\": \"analysis_agent\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"error_agent\", \"execute_sql\")\n",
    "    workflow.add_edge(\"analysis_agent\", \"decide_graph_need\")\n",
    "    \n",
    "    # Conditional edge for graph generation\n",
    "    workflow.add_conditional_edges(\n",
    "        \"decide_graph_need\",\n",
    "        should_generate_graph,\n",
    "        {\n",
    "            \"viz_agent\": \"viz_agent\",\n",
    "            \"skip_graph\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"viz_agent\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Create the compiled graph\n",
    "text2sql_graph = create_text2sql_graph()\n",
    "\n",
    "## Defining the function to generate LangGraph flow visualization\n",
    "\n",
    "def generate_graph_visualization(output_path: str = \"text2sql_workflow.png\") -> str:\n",
    "    \"\"\"\n",
    "    Generate a PNG visualization of the LangGraph workflow.\n",
    "    \n",
    "    Args:\n",
    "        output_path: Path where the PNG file will be saved (default: \"text2sql_workflow.png\")\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the generated PNG file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the graph visualization\n",
    "        graph_image = text2sql_graph.get_graph().draw_mermaid_png()\n",
    "        \n",
    "        # Save to file\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(graph_image)\n",
    "        \n",
    "        print(f\"Graph visualization saved to: {output_path}\")\n",
    "        return output_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating graph visualization: {e}\")\n",
    "        print(\"Make sure you have 'pygraphviz' or 'grandalf' installed:\")\n",
    "        print(\"  pip install pygraphviz\")\n",
    "        print(\"  or\")\n",
    "        print(\"  pip install grandalf\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d171ff3d-9182-4e2b-a14a-bf0a29e85660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph visualization saved to: text2sql_workflow.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'text2sql_workflow.png'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_graph_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065774bd-ce97-4de1-ae8b-c6ef81a95460",
   "metadata": {},
   "source": [
    "## Process Question Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a51c4a1-6e0f-4f50-9012-94fc9f9dd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_question_stream(question: str):\n",
    "    \"\"\"\n",
    "    Process a natural language question and stream node execution events.\n",
    "    This is an async generator that yields node events for debugging visualization.\n",
    "    \n",
    "    Yields:\n",
    "        dict: Event with type ('node_start', 'node_end', 'error', 'final') and data\n",
    "    \"\"\"\n",
    "    initial_state = AgentState(\n",
    "        question=question,\n",
    "        sql_query=\"\",\n",
    "        query_result=\"\",\n",
    "        final_answer=\"\",\n",
    "        error=\"\",\n",
    "        iteration=0,\n",
    "        needs_graph=False,\n",
    "        graph_type=\"\",\n",
    "        graph_json=\"\",\n",
    "        is_in_scope=True\n",
    "    )\n",
    "    \n",
    "    current_state = initial_state.copy()\n",
    "    \n",
    "    try:\n",
    "        # Stream events from the graph\n",
    "        async for event in text2sql_graph.astream_events(\n",
    "            initial_state,\n",
    "            config={\"recursion_limit\": 50},\n",
    "            version=\"v1\"\n",
    "        ):\n",
    "            event_type = event.get(\"event\")\n",
    "            \n",
    "            # Node start event\n",
    "            if event_type == \"on_chain_start\":\n",
    "                node_name = event.get(\"name\", \"\")\n",
    "                if node_name in [\"check_guardrails\", \"generate_sql\", \"execute_sql\", \"generate_answer\", \n",
    "                               \"handle_error\", \"decide_graph_need\", \"generate_graph\"]:\n",
    "                    yield {\n",
    "                        \"type\": \"node_start\",\n",
    "                        \"node\": node_name,\n",
    "                        \"input\": current_state\n",
    "                    }\n",
    "            \n",
    "            # Node end event\n",
    "            elif event_type == \"on_chain_end\":\n",
    "                node_name = event.get(\"name\", \"\")\n",
    "                if node_name in [\"check_guardrails\", \"generate_sql\", \"execute_sql\", \"generate_answer\", \n",
    "                               \"handle_error\", \"decide_graph_need\", \"generate_graph\"]:\n",
    "                    output = event.get(\"data\", {}).get(\"output\", {})\n",
    "                    if output:\n",
    "                        current_state.update(output)\n",
    "                        yield {\n",
    "                            \"type\": \"node_end\",\n",
    "                            \"node\": node_name,\n",
    "                            \"output\": output,\n",
    "                            \"state\": current_state.copy()\n",
    "                        }\n",
    "        \n",
    "        # Send final result\n",
    "        yield {\n",
    "            \"type\": \"final\",\n",
    "            \"result\": current_state\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        yield {\n",
    "            \"type\": \"error\",\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436dfcb-8e18-48a2-a8d7-2cb0836d12e2",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cd0e3d8-748e-4fea-9cfa-123297270712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Text2SQL Agent - Use 'chainlit run app.py' to start the web interface\n",
      "================================================================================\n",
      "\n",
      "This module is meant to be imported and used via the Chainlit app.\n",
      "Run: chainlit run app.py\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Test the agent\n",
    "#     print(\"=\" * 80)\n",
    "#     print(\"Text2SQL Agent - Use 'chainlit run app.py' to start the web interface\")\n",
    "#     print(\"=\" * 80)\n",
    "#     print(\"\\nThis module is meant to be imported and used via the Chainlit app.\")\n",
    "#     print(\"Run: chainlit run app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d737f0e-6b27-4eb7-ab5d-5ef785b55fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the process question\n",
    "\n",
    "def process_question(question: str) -> dict:\n",
    "    \"\"\"\n",
    "    Process a natural language question and return the final result.\n",
    "    This is a simple synchronous function for notebook usage.\n",
    "    \n",
    "    Args:\n",
    "        question: Natural language question about the e-commerce data\n",
    "        \n",
    "    Returns:\n",
    "        dict: Final state with answer, SQL query, and graph data if applicable\n",
    "    \"\"\"\n",
    "    initial_state = AgentState(\n",
    "        question=question,\n",
    "        sql_query=\"\",\n",
    "        query_result=\"\",\n",
    "        final_answer=\"\",\n",
    "        error=\"\",\n",
    "        iteration=0,\n",
    "        needs_graph=False,\n",
    "        graph_type=\"\",\n",
    "        graph_json=\"\",\n",
    "        is_in_scope=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Invoke the graph\n",
    "        final_state = text2sql_graph.invoke(\n",
    "            initial_state,\n",
    "            config={\"recursion_limit\": 50}\n",
    "        )\n",
    "        \n",
    "        return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"final_answer\": f\"An error occurred while processing your question: {str(e)}\"\n",
    "        }\n",
    "\n",
    "## Define the test function:\n",
    "\n",
    "def test_process_question(question: str):\n",
    "\n",
    "    result = process_question(question)\n",
    "    \n",
    "    print(\"Final Answer:\")\n",
    "    print(result.get(\"final_answer\", \"No answer generated.\"))\n",
    "\n",
    "    if result.get(\"sql_query\"):\n",
    "    \n",
    "        print(\"\\nGenerated SQL Query:\")\n",
    "        print(result.get(\"sql_query\", \"No SQL query generated.\"))\n",
    "\n",
    "    print(f\"\\nNeeds Graph: {result['needs_graph']}\")\n",
    "    if result['needs_graph']:\n",
    "        print(f\"Graph Type: {result['graph_type']}\")\n",
    "    \n",
    "    if result.get(\"graph_json\"):\n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.io as pio\n",
    "    \n",
    "        # Load the figure from JSON\n",
    "        fig = pio.from_json(result['graph_json'])\n",
    "        \n",
    "        # Display in notebook\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"No graph was generated for this question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c041ce-00b0-4616-90dc-3b5a771f8e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
